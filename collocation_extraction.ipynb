{
 "metadata": {
  "name": "",
  "signature": "sha256:60a46db55da81c052499f983e320f22ea329215c5722489930f485d0de3ecdbb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import nltk\n",
      "from   unidecode import unidecode"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "wd      = './corpus2/' # Directory to a set of *.txt files comprising the corpus.\n",
      "stemmer = nltk.stem.wordnet.WordNetLemmatizer() # Uses WordNet to stem. Other main option is Porter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "corpus   = nltk.corpus.PlaintextCorpusReader(wd,'out')          # 1. Read in the corpus\n",
      "raw_toks = nltk.tokenize.word_tokenize(unidecode(corpus.raw())) # 2. Get \"raw\" decoded tokens\n",
      "tokens   = [stemmer.lemmatize(t) for t in raw_toks]             # 3. Lemmatize / stem the tokens\n",
      "finder   = nltk.BigramCollocationFinder.from_words(tokens)      # 4. Construct a collocation factory\n",
      "finder.score_ngrams(nltk.BigramAssocMeasures.mi_like)[0:20]     # 5. Calculate the strongest collocations and show the top 20"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[(('et', 'al.'), 273.39729905849043),\n",
        " (('.', 'The'), 238.5169792154347),\n",
        " (('Computational', 'Linguistics'), 155.322157930565),\n",
        " (('of', 'the'), 134.35174578239955),\n",
        " (('.', 'In'), 131.18107441060903),\n",
        " (('can', 'be'), 127.22108890938732),\n",
        " (('et', 'al'), 79.44087647857282),\n",
        " (('based', 'on'), 76.71922219499947),\n",
        " (('zero', u'pronoun'), 71.05109856883693),\n",
        " (('Natural', 'Language'), 55.256539235412475),\n",
        " ((',', 'we'), 49.29579244802532),\n",
        " (('Annual', 'Meeting'), 45.378151260504204),\n",
        " (('Partition', 'Search'), 43.17259552042161),\n",
        " (('In', 'Proceedings'), 42.41220043572985),\n",
        " (('Named', 'Entity'), 40.32258064516129),\n",
        " (('named', u'entity'), 40.226272784412316),\n",
        " (('in', 'the'), 38.27597236502735),\n",
        " (('.', 'We'), 36.80077865938149),\n",
        " ((')', '.'), 33.73271431155024),\n",
        " (('number', 'of'), 33.2391039360812)]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def load_openwords():\n",
      "    r = []\n",
      "    \n",
      "    fin = open(wd + \"../dictionary.txt\", \"r\")\n",
      "    for w in fin: r.append(w.lower().rstrip(\"\\n\"))\n",
      "    fin.close()\n",
      "\n",
      "    return r\n",
      "\n",
      "stpwds      = set(nltk.corpus.stopwords.words('english'))\n",
      "valid_words = set(load_openwords())\n",
      "valid_words = {stemmer.lemmatize(t) for t in valid_words} - {stemmer.lemmatize(t) for t in stpwds}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# 1. Re-lemmatize \n",
      "# We need the ordering ... otherwise an intersection would be faster than testing:\n",
      "tokens = [stemmer.lemmatize(t) for t in raw_toks if t in valid_words]\n",
      "\n",
      "# Reconstruct the collocation finder:\n",
      "finder = nltk.BigramCollocationFinder.from_words(tokens)\n",
      "\n",
      "# Re-display the top 20 collocations:\n",
      "finder.score_ngrams(nltk.BigramAssocMeasures.mi_like)[0:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[(('activate', 'bind'), 1.0),\n",
        " (('adnominal', 'hara'), 1.0),\n",
        " (('aided', 'staff'), 1.0),\n",
        " (('airline', 'ticket'), 1.0),\n",
        " (('armed', 'armored'), 1.0),\n",
        " (('astrology', 'microwave'), 1.0),\n",
        " (('autocar', 'motorcar'), 1.0),\n",
        " (('awake', 'girl'), 1.0),\n",
        " (('basin', 'attraction'), 1.0),\n",
        " (('bat', 'glove'), 1.0),\n",
        " (('baxter', 'corwin'), 1.0),\n",
        " (('beat', 'campaign'), 1.0),\n",
        " (('bird', 'colorful'), 1.0),\n",
        " (('bite', 'cut'), 1.0),\n",
        " (('blood', 'sucker'), 1.0),\n",
        " (('blow', 'strain'), 1.0),\n",
        " (('board', 'nonexecutive'), 1.0),\n",
        " (('bothered', 'fruitless'), 1.0),\n",
        " (('bottle', 'boat'), 1.0),\n",
        " (('broccoli', 'coconut'), 1.0)]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "finder.score_ngrams(nltk.BigramAssocMeasures.mi_like)[20:50]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[(('named', 'entity'), 7.617054263565891),\n",
        " (('real', 'situation'), 6.75),\n",
        " (('dominance', 'chain'), 6.0),\n",
        " (('edible', 'fruit'), 6.0),\n",
        " (('linearly', 'separable'), 6.0),\n",
        " (('uniquely', 'instantiated'), 6.0),\n",
        " (('wallet', 'stolen'), 6.0),\n",
        " (('vector', 'space'), 5.7069949395255355),\n",
        " (('prefix', 'suffix'), 5.6953125),\n",
        " (('topic', 'detection'), 5.6066666666666665),\n",
        " (('masu', 'ka'), 5.12),\n",
        " (('maximum', 'entropy'), 4.821428571428571),\n",
        " (('error', 'rate'), 4.706325301204819),\n",
        " (('theorem', 'provers'), 4.5),\n",
        " (('disparity', 'topical'), 4.464285714285714),\n",
        " (('price', 'competition'), 4.4366666666666665),\n",
        " (('ambiguity', 'resolution'), 4.114285714285714),\n",
        " (('proposed', 'method'), 4.046239016509713),\n",
        " (('countably', 'uncountably'), 4.0),\n",
        " (('defense', 'fight'), 4.0),\n",
        " (('feroz', 'negro'), 4.0),\n",
        " (('gato', 'feroz'), 4.0),\n",
        " (('nicht', 'sind'), 4.0),\n",
        " (('schwab', 'prince'), 4.0),\n",
        " (('triangular', 'inequality'), 4.0),\n",
        " (('tama', 'red'), 3.908831908831909),\n",
        " (('book', 'online'), 3.90625),\n",
        " (('fully', 'countable'), 3.7363945578231292),\n",
        " (('target', 'word'), 3.63933131499276),\n",
        " (('conditional', 'probability'), 3.2846715328467155)]"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}